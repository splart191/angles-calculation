{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea29ff0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved successfully: E:/fengyun/code/output/result.nc\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Map elevation, ERA5 annual mean temperature/pressure, and FY-4B scan time to the LUT grid.\n",
    "\n",
    "========================================================================================\n",
    "Function\n",
    "----------------------------------------------------------------------------------------\n",
    "map_elev_era5_scan_to_lut_safe()\n",
    "\n",
    "========================================================================================\n",
    "Purpose\n",
    "----------------------------------------------------------------------------------------\n",
    "This function maps high-resolution terrain elevation (m), ERA5 annual mean\n",
    "2-meter air temperature (K) and surface pressure (Pa), as well as FY-4B AGRI\n",
    "scan time (UTC), onto the grid defined by the FY-4B GEO Look-Up Table (LUT).\n",
    "The resulting dataset is saved as a unified NetCDF file.\n",
    "\n",
    "========================================================================================\n",
    "Input Files and Variables\n",
    "----------------------------------------------------------------------------------------\n",
    "elev_file : str  \n",
    "    Path to the elevation dataset (NetCDF format).  \n",
    "    Example: `\"world_ll_elev_0.05deg.nc4\"`  \n",
    "    Variables:\n",
    "        - `latitude`  [degrees_north]  \n",
    "        - `longitude` [degrees_east]  \n",
    "        - `elevation` [m]\n",
    "\n",
    "era5_file : str  \n",
    "    Path to the ERA5 monthly mean dataset (NetCDF format).  \n",
    "    Example: `\"2024monthly.nc\"`  \n",
    "    Variables:\n",
    "        - `t2m` [K]  ‚Üí 2-meter air temperature  \n",
    "        - `sp`  [Pa] ‚Üí surface pressure  \n",
    "    Dimensions:\n",
    "        `(month, latitude, longitude)`  \n",
    "    The function calculates the annual mean for each variable.\n",
    "\n",
    "lut_file : str  \n",
    "    Path to the FY-4B GEO LUT file (binary .raw format).  \n",
    "    Example: `\"FY4B-_DISK_1050E_GEO_NOM_LUT_20240227000000_4000M_V0001.raw\"`  \n",
    "    Description:\n",
    "        - Binary file containing latitude and longitude pairs  \n",
    "        - Shape: (2748, 2748, 2)  \n",
    "        - Each element corresponds to a pixel location on the FY-4B disk view  \n",
    "    Units:\n",
    "        - degrees_north, degrees_east\n",
    "\n",
    "hdf_file : str  \n",
    "    Path to the FY-4B AGRI Level-1 observation file (HDF format).  \n",
    "    Example:  \n",
    "        `\"FY4B-_AGRI--_N_DISK_1050E_L1-_FDI-_MULT_NOM_20240923040000_20240923041459_4000M_V0001.HDF\"`  \n",
    "    Dataset:\n",
    "        - `\"NOMObs/NOMObsTime\"` ‚Üí Start and end UTC time of each scan line  \n",
    "          Format: integer `YYYYMMDDHHMMSSsss` (UTC, with millisecond precision)\n",
    "\n",
    "out_file : str  \n",
    "    Path to the output NetCDF file where all mapped variables will be saved.  \n",
    "    Example: `\"result.nc\"`\n",
    "\n",
    "========================================================================================\n",
    "Output File (NetCDF4 format)\n",
    "----------------------------------------------------------------------------------------\n",
    "Dimensions:\n",
    "    - `y = 2748`\n",
    "    - `x = 2748`\n",
    "\n",
    "Variables:\n",
    "    - `latitude(y, x)`   [degrees_north] ‚Üí LUT grid latitude  \n",
    "    - `longitude(y, x)`  [degrees_east]  ‚Üí LUT grid longitude  \n",
    "    - `altitude(y, x)`   [m]             ‚Üí Mapped elevation  \n",
    "    - `t2m(y, x)`        [K]             ‚Üí ERA5 annual mean 2-m air temperature  \n",
    "    - `sp(y, x)`         [Pa]            ‚Üí ERA5 annual mean surface pressure  \n",
    "    - `scan_time(y, x)`  [int64, UTC]    ‚Üí Per-pixel scan time interpolated\n",
    "                                           from start and end line times,\n",
    "                                           formatted as `YYYYMMDDHHMMSSsss`\n",
    "\n",
    "========================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import h5py\n",
    "import os\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "def map_elev_era5_scan_to_lut_safe(\n",
    "    elev_file: str,\n",
    "    era5_file: str,\n",
    "    lut_file: str,\n",
    "    hdf_file: str,\n",
    "    out_file: str\n",
    "):\n",
    "\n",
    "\n",
    "    # ---------------- 1. Read elevation data ----------------\n",
    "    with Dataset(elev_file, 'r') as nc:\n",
    "        lat_elev = nc.variables['latitude'][:]   # degrees_north\n",
    "        lon_elev = nc.variables['longitude'][:]  # degrees_east\n",
    "        elev     = nc.variables['elevation'][:]  # meters\n",
    "\n",
    "    # ---------------- 2. Read FY-4B LUT (lat/lon grid) ----------------\n",
    "    raw_image = np.fromfile(lut_file)\n",
    "    raw_image = raw_image.reshape(-1, 2)\n",
    "    lat_lut   = raw_image[:, 0].reshape(2748, 2748)\n",
    "    lon_lut   = raw_image[:, 1].reshape(2748, 2748)\n",
    "    mask = (lat_lut > 999) | (lon_lut > 999)\n",
    "    valid = ~mask\n",
    "    ny, nx = lat_lut.shape\n",
    "\n",
    "    # ---------------- 3. Map elevation to LUT grid ----------------\n",
    "    # Use nearest neighbor index mapping\n",
    "    def nearest_idx(src_coords, target_coords):\n",
    "        idx = np.searchsorted(src_coords, target_coords, side=\"left\")\n",
    "        idx = np.clip(idx, 1, len(src_coords)-1)\n",
    "        idx = idx - (np.abs(target_coords - src_coords[idx-1]) < np.abs(target_coords - src_coords[idx]))\n",
    "        return idx\n",
    "\n",
    "    lat_idx_elev = nearest_idx(lat_elev, lat_lut)\n",
    "    lon_idx_elev = nearest_idx(lon_elev, lon_lut)\n",
    "    elev_resampled = np.full(lat_lut.shape, np.nan)\n",
    "    elev_resampled[valid] = elev[lat_idx_elev[valid], lon_idx_elev[valid]]\n",
    "\n",
    "    # ---------------- 4. Read ERA5 monthly data and compute annual mean ----------------\n",
    "    with Dataset(era5_file, 'r') as nc:\n",
    "        t2m_monthly = nc.variables['t2m'][:]  # [K]\n",
    "        sp_monthly  = nc.variables['sp'][:]   # [Pa]\n",
    "        lat_era5    = nc.variables['latitude'][:]\n",
    "        lon_era5    = nc.variables['longitude'][:]\n",
    "\n",
    "    t2m_annual = np.mean(t2m_monthly, axis=0)\n",
    "    sp_annual  = np.mean(sp_monthly, axis=0)\n",
    "\n",
    "    # ---------------- 5. Interpolate ERA5 data to LUT grid ----------------\n",
    "    # If ERA5 latitude is descending, reverse it for correct interpolation\n",
    "    t2m_interp = RegularGridInterpolator(\n",
    "        (lat_era5[::-1], lon_era5),\n",
    "        t2m_annual[::-1, :],\n",
    "        bounds_error=False,\n",
    "        fill_value=np.nan\n",
    "    )\n",
    "    sp_interp = RegularGridInterpolator(\n",
    "        (lat_era5[::-1], lon_era5),\n",
    "        sp_annual[::-1, :],\n",
    "        bounds_error=False,\n",
    "        fill_value=np.nan\n",
    "    )\n",
    "\n",
    "    points = np.stack([lat_lut.ravel(), lon_lut.ravel()], axis=-1)\n",
    "    t2m_resampled = t2m_interp(points).reshape(lat_lut.shape)\n",
    "    sp_resampled  = sp_interp(points).reshape(lat_lut.shape)\n",
    "\n",
    "    # ---------------- 6. Read FY-4B HDF scan times ----------------\n",
    "    with h5py.File(hdf_file, 'r') as f:\n",
    "        scan_time_raw = f[\"NOMObs/NOMObsTime\"][:]  # shape: (ny_raw, 2)\n",
    "\n",
    "    # Extract start and end timestamps from filename\n",
    "    filename = os.path.basename(hdf_file)\n",
    "    parts = filename.split('_')\n",
    "    start_str = parts[-4]\n",
    "    end_str   = parts[-3]\n",
    "    ts_start = int(start_str + \"000\")\n",
    "    te_end   = int(end_str + \"000\")\n",
    "\n",
    "    # Replace invalid scan times (marked as 9999)\n",
    "    ny_raw = scan_time_raw.shape[0]\n",
    "    for i in range(ny_raw):\n",
    "        ts, te = scan_time_raw[i]\n",
    "        if ts == 9999 and te == 9999:\n",
    "            if i < ny_raw // 2:\n",
    "                scan_time_raw[i, 0] = ts_start\n",
    "                scan_time_raw[i, 1] = ts_start\n",
    "            else:\n",
    "                scan_time_raw[i, 0] = te_end\n",
    "                scan_time_raw[i, 1] = te_end\n",
    "\n",
    "    # Helper functions for time conversion\n",
    "    def parse_time(ts_int):\n",
    "        \"\"\"Convert FY-4B integer timestamp to Python datetime.\"\"\"\n",
    "        ts_str = f\"{int(ts_int):017d}\"\n",
    "        dt = datetime.strptime(ts_str[:14], \"%Y%m%d%H%M%S\")\n",
    "        ms = int(ts_str[14:])\n",
    "        return dt + timedelta(milliseconds=ms)\n",
    "\n",
    "    def datetime_to_unix(dt):\n",
    "        \"\"\"Convert datetime to UNIX seconds (float).\"\"\"\n",
    "        return dt.replace(tzinfo=timezone.utc).timestamp()\n",
    "\n",
    "    def unix_to_int(ts):\n",
    "        \"\"\"Convert UNIX seconds to FY-4B integer timestamp format.\"\"\"\n",
    "        dt = datetime.fromtimestamp(ts, tz=timezone.utc)\n",
    "        ms = int(dt.microsecond / 1000)\n",
    "        return int(dt.strftime(\"%Y%m%d%H%M%S\") + f\"{ms:03d}\")\n",
    "\n",
    "    # ---------------- 7. Interpolate scan time across each scan line ----------------\n",
    "    scan_time_sec = np.full((ny, nx), np.nan, dtype=np.float64)\n",
    "    for i in range(ny):\n",
    "        ts_int, te_int = scan_time_raw[i]\n",
    "        dt_start = parse_time(ts_int)\n",
    "        dt_end   = parse_time(te_int)\n",
    "        ts_sec = datetime_to_unix(dt_start)\n",
    "        te_sec = datetime_to_unix(dt_end)\n",
    "\n",
    "        valid_cols = np.where(valid[i, :])[0]\n",
    "        n_valid = len(valid_cols)\n",
    "        if n_valid > 0:\n",
    "            scan_time_sec[i, valid_cols] = np.linspace(ts_sec, te_sec, n_valid)\n",
    "\n",
    "    # Convert interpolated UNIX seconds back to FY-4B integer timestamp format\n",
    "    scan_time_int = np.full((ny, nx), 0, dtype=np.int64)\n",
    "    valid_idx = ~np.isnan(scan_time_sec)\n",
    "    scan_time_int[valid_idx] = np.vectorize(unix_to_int)(scan_time_sec[valid_idx])\n",
    "\n",
    "    # ---------------- 8. Write all mapped data to NetCDF ----------------\n",
    "    ds_out = Dataset(out_file, 'w', format='NETCDF4')\n",
    "    ds_out.createDimension('y', ny)\n",
    "    ds_out.createDimension('x', nx)\n",
    "\n",
    "    # Define variables\n",
    "    lat_var  = ds_out.createVariable('latitude',  'f8', ('y','x'))\n",
    "    lon_var  = ds_out.createVariable('longitude', 'f8', ('y','x'))\n",
    "    elev_var = ds_out.createVariable('altitude',  'f8', ('y','x'), fill_value=np.nan)\n",
    "    t2m_var  = ds_out.createVariable('t2m',       'f8', ('y','x'), fill_value=np.nan)\n",
    "    sp_var   = ds_out.createVariable('sp',        'f8', ('y','x'), fill_value=np.nan)\n",
    "    scan_var = ds_out.createVariable('scan_time', 'i8', ('y','x'), fill_value=0)\n",
    "\n",
    "    # Assign data\n",
    "    lat_var[:, :]   = lat_lut\n",
    "    lon_var[:, :]   = lon_lut\n",
    "    elev_var[:, :]  = elev_resampled\n",
    "    t2m_var[:, :]   = t2m_resampled\n",
    "    sp_var[:, :]    = sp_resampled\n",
    "    scan_var[:, :]  = scan_time_int\n",
    "\n",
    "    # Add metadata\n",
    "    lat_var.units  = 'degrees_north'\n",
    "    lon_var.units  = 'degrees_east'\n",
    "    elev_var.units = 'm'\n",
    "    t2m_var.units  = 'K'\n",
    "    sp_var.units   = 'Pa'\n",
    "    scan_var.units = 'YYYYMMDDHHMMSSsss (UTC)'\n",
    "\n",
    "    elev_var.description = 'High-resolution elevation mapped to LUT grid'\n",
    "    t2m_var.description  = 'ERA5 annual mean 2-meter temperature mapped to LUT grid'\n",
    "    sp_var.description   = 'ERA5 annual mean surface pressure mapped to LUT grid'\n",
    "    scan_var.description = 'FY-4B scan time interpolated from line start/end times, UTC with millisecond precision'\n",
    "\n",
    "    ds_out.close()\n",
    "    print(\"‚úÖ Saved successfully:\", out_file)\n",
    "\n",
    "\n",
    "# ================= Example Usage =================\n",
    "elev_file = \"E:/fengyun/code/input/world_ll_elev_0.05deg.nc4\"\n",
    "era5_file = \"E:/fengyun/code/input/2024monthly.nc\"\n",
    "lut_file  = \"E:/fengyun/code/input/FY4B-_DISK_1050E_GEO_NOM_LUT_20240227000000_4000M_V0001.raw\"\n",
    "hdf_file  = \"E:/fengyun/code/input/FY4B-_AGRI--_N_DISK_1050E_L1-_FDI-_MULT_NOM_20240923040000_20240923041459_4000M_V0001.HDF\"\n",
    "out_file  = \"E:/fengyun/code/output/result.nc\"\n",
    "\n",
    "map_elev_era5_scan_to_lut_safe(elev_file, era5_file, lut_file, hdf_file, out_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c25f9eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fast & accurate solar position computation completed and saved to: E:/fengyun/code/output/result.nc\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fast Solar Position Computation using pvlib SPA\n",
    "-----------------------------------------------\n",
    "\n",
    "This script computes solar position parameters (e.g., zenith, azimuth, and equation of time)\n",
    "for each pixel in a Look-Up Table (LUT) stored as a NetCDF file. It employs pvlib‚Äôs\n",
    "high-accuracy Solar Position Algorithm (SPA) and supports parallel computation for\n",
    "large LUT datasets. The implementation is optimized for modern NumPy versions\n",
    "(>= 1.24) and ensures fast, accurate, and memory-efficient solar geometry calculation.\n",
    "\n",
    "------------------------------------------------------------------------------\n",
    "üîπ INPUT\n",
    "------------------------------------------------------------------------------\n",
    "The function reads the following variables from the input NetCDF LUT file:\n",
    "\n",
    "- **latitude**   (2D array, degrees)  \n",
    "- **longitude**  (2D array, degrees)  \n",
    "- **altitude**   (2D array, meters above sea level)  \n",
    "- **t2m**        (2D array, air temperature in Kelvin , K)  \n",
    "- **sp**         (2D array, surface air pressure in Pascals, Pa)  \n",
    "- **scan_time**  (2D array, 17-digit integer UTC timestamps,  \n",
    "                  e.g., `20250101053045123` ‚Üí 2025-01-01 05:30:45.123 UTC)\n",
    "\n",
    "Optional parameters:\n",
    "- **delta_t** : float  \n",
    "  Difference between Terrestrial Time (TT) and UT1 in seconds.  \n",
    "  Typical value ‚âà 67‚Äì70 s (default: 67.0).  \n",
    "\n",
    "- **numthreads** : int  \n",
    "  Number of CPU threads used for parallel computation (default: 4).\n",
    "\n",
    "------------------------------------------------------------------------------\n",
    "üîπ OUTPUT\n",
    "------------------------------------------------------------------------------\n",
    "The computed solar geometry parameters are written **back into the same NetCDF file**.\n",
    "New variables will be created if they do not already exist:\n",
    "\n",
    "1. **apparent_zenith**       (degrees)  \n",
    "2. **zenith**                (degrees)  \n",
    "3. **azimuth**               (degrees)  \n",
    "4. **equation_of_time**      (minutes)\n",
    "\n",
    "Each variable is stored as a 2D array with the same dimensions as the latitude/longitude grids.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from netCDF4 import Dataset\n",
    "from joblib import Parallel, delayed\n",
    "import pvlib\n",
    "\n",
    "def compute_solarposition_nc_fast(nc_file, delta_t=67.0, numthreads=4):\n",
    "\n",
    "\n",
    "    ds = Dataset(nc_file, 'r+')\n",
    "    try:\n",
    "        # ---------------- 1. Read variables ----------------\n",
    "        lat = ds['latitude'][:]\n",
    "        lon = ds['longitude'][:]\n",
    "        elev = ds['altitude'][:]\n",
    "        scan_time_int = ds['scan_time'][:]\n",
    "        t2m = ds['t2m'][:]   # K\n",
    "        sp  = ds['sp'][:]    # Pa\n",
    "\n",
    "        ny, nx = lat.shape\n",
    "        valid_mask = ~np.isnan(lat) & (scan_time_int > 0)\n",
    "        scan_time_valid = scan_time_int[valid_mask].astype(np.int64)\n",
    "\n",
    "        # ---------------- 2. Accurate vectorized time parsing ----------------\n",
    "        # Ensure all values are 17-digit zero-padded strings\n",
    "        ts_str = np.char.zfill(scan_time_valid.astype(str), 17)\n",
    "\n",
    "        # Extract first 14 digits (datetime part) and last 3 digits (milliseconds)\n",
    "        dt_part = np.array([s[:14] for s in ts_str])\n",
    "        ms_part = np.array([s[14:] for s in ts_str]).astype(np.int64)\n",
    "\n",
    "        # Convert to datetime + milliseconds\n",
    "        time_flat = pd.to_datetime(dt_part, format='%Y%m%d%H%M%S', utc=True)\n",
    "        time_flat = time_flat + pd.to_timedelta(ms_part, unit='ms')\n",
    "\n",
    "        # ---------------- 3. Flatten valid variables ----------------\n",
    "        lat_flat = lat[valid_mask]\n",
    "        lon_flat = lon[valid_mask]\n",
    "        elev_flat = elev[valid_mask]\n",
    "        pressure_flat = sp[valid_mask]\n",
    "        temperature_flat = t2m[valid_mask] - 273.15  # K -> ¬∞C\n",
    "\n",
    "        # ---------------- 4. Parallel chunked SPA computation ----------------\n",
    "        n = len(time_flat)\n",
    "        if n == 0:\n",
    "            print(\"‚ö†Ô∏è No valid scan_time entries found. Exiting.\")\n",
    "            return\n",
    "\n",
    "        n_jobs = min(numthreads, max(1, os.cpu_count() or 1))\n",
    "        chunk_size = int(np.ceil(n / n_jobs))\n",
    "        chunks = [(i, min(i + chunk_size, n)) for i in range(0, n, chunk_size)]\n",
    "\n",
    "        def compute_chunk(ch):\n",
    "            s, e = ch\n",
    "            return pvlib.solarposition.spa_python(\n",
    "                time=time_flat[s:e],\n",
    "                latitude=lat_flat[s:e],\n",
    "                longitude=lon_flat[s:e],\n",
    "                altitude=elev_flat[s:e],\n",
    "                pressure=pressure_flat[s:e],\n",
    "                temperature=temperature_flat[s:e],\n",
    "                delta_t=delta_t,\n",
    "                how='numpy'\n",
    "            )\n",
    "\n",
    "        results = Parallel(n_jobs=n_jobs, prefer='threads')(\n",
    "            delayed(compute_chunk)(ch) for ch in chunks\n",
    "        )\n",
    "\n",
    "        solpos_flat = pd.concat(results, ignore_index=True)\n",
    "\n",
    "        # ---------------- 5. Reconstruct 2D grids ----------------\n",
    "        def to_grid(colname):\n",
    "            grid = np.full((ny, nx), np.nan, dtype=np.float32)\n",
    "            grid[valid_mask] = solpos_flat[colname].values\n",
    "            return grid\n",
    "\n",
    "        output_vars = {\n",
    "            'apparent_zenith':      ('degrees', to_grid('apparent_zenith')),\n",
    "            'zenith':               ('degrees', to_grid('zenith')),\n",
    "            # 'apparent_elevation':   ('degrees', to_grid('apparent_elevation')),\n",
    "            # 'elevation':            ('degrees', to_grid('elevation')),\n",
    "            'azimuth':              ('degrees', to_grid('azimuth')),\n",
    "            'equation_of_time':     ('minutes', to_grid('equation_of_time')),\n",
    "        }\n",
    "\n",
    "        # ---------------- 6. Write results back to NetCDF ----------------\n",
    "        for name, (units, data) in output_vars.items():\n",
    "            if name in ds.variables:\n",
    "                ds[name][:] = data\n",
    "            else:\n",
    "                var = ds.createVariable(\n",
    "                    name, 'f8', ('y', 'x'),\n",
    "                    zlib=True, complevel=4, fill_value=np.nan\n",
    "                )\n",
    "                var.units = units\n",
    "                var[:, :] = data\n",
    "\n",
    "        print(f\"‚úÖ Fast & accurate solar position computation completed and saved to: {nc_file}\")\n",
    "\n",
    "    finally:\n",
    "        ds.close()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    nc_file = \"E:/fengyun/code/output/result.nc\"\n",
    "    compute_solarposition_nc_fast(nc_file, delta_t=69.1322, numthreads=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b38e411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Viewing zenith (Œ∏) and azimuth (œÜ) angles have been successfully written to the NetCDF file.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FY-4B Satellite Viewing Angle Computation\n",
    "-----------------------------------------\n",
    "\n",
    "This script defines a function to compute the *viewing geometry* (zenith and azimuth angles)\n",
    "from the FY-4B geostationary satellite to each ground point. The computation is based on\n",
    "the latitude, longitude, and terrain elevation (altitude) grids stored in a NetCDF file.\n",
    "\n",
    "The results represent the line-of-sight direction from the ground to the satellite\n",
    "and are written back to the same NetCDF file.\n",
    "\n",
    "------------------------------------------------------------------------------\n",
    "üîπ INPUT\n",
    "------------------------------------------------------------------------------\n",
    "The function reads the following variables from the input NetCDF file:\n",
    "\n",
    "- **latitude**  (2D array, degrees)\n",
    "- **longitude** (2D array, degrees)\n",
    "- **altitude**  (2D array, meters above sea level , m)\n",
    "\n",
    "Optional parameters:\n",
    "- **sat_lon_deg** : Satellite sub-point longitude in degrees (default = 105.0¬∞ for FY-4B)\n",
    "- **sat_height**  : Satellite orbital height in meters (default = 35,786,000 m)\n",
    "\n",
    "------------------------------------------------------------------------------\n",
    "üîπ OUTPUT\n",
    "------------------------------------------------------------------------------\n",
    "The function writes two new variables back into the *same* NetCDF file:\n",
    "\n",
    "1. **satellite_zenith_angle**  \n",
    "   - Unit: degrees  \n",
    "   - Description: Angle between the local zenith and the satellite line-of-sight  \n",
    "     (0¬∞ = directly overhead, 90¬∞ = horizon)\n",
    "\n",
    "2. **satellite_azimuth_angle**  \n",
    "   - Unit: degrees  \n",
    "   - Description: Azimuth of the satellite direction on the local horizontal plane,  \n",
    "     measured clockwise from north (0‚Äì360¬∞)\n",
    "\n",
    "Both variables are 2D arrays matching the latitude/longitude grid shape.\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import numpy as np \n",
    "from netCDF4 import Dataset\n",
    "\n",
    "def compute_satellite_angles(nc_file: str, sat_lon_deg: float = 105.0, sat_height: float = 35786000.0):\n",
    "    \"\"\"\n",
    "    Compute viewing zenith angle (Œ∏) and azimuth angle (œÜ) from FY-4B satellite\n",
    "    to the ground, and write them to the input NetCDF file.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    nc_file : str\n",
    "        Input/output NetCDF file containing 'latitude', 'longitude', and 'altitude'.\n",
    "    sat_lon_deg : float, optional\n",
    "        Satellite longitude in degrees (default is 105.0¬∞ for FY-4B).\n",
    "    sat_height : float, optional\n",
    "        Satellite orbit height in meters (default is 35786000 m).\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------------- Step 1: Open NetCDF file ----------------\n",
    "    nc = Dataset(nc_file, 'r+')\n",
    "\n",
    "    # ---------------- Step 2: Read latitude, longitude, and altitude ----------------\n",
    "    lat_arr = np.array(nc.variables['latitude'][:], dtype=np.float64)\n",
    "    lon_arr = np.array(nc.variables['longitude'][:], dtype=np.float64)\n",
    "    height_arr = np.array(nc.variables['altitude'][:], dtype=np.float64)\n",
    "\n",
    "    # ---------------- Step 3: Satellite and Earth parameters (GRS80) ----------------\n",
    "    a = 6378137.0                   # Equatorial radius (m)\n",
    "    f = 1 / 298.257222101           # Flattening\n",
    "    E2 = 2 * f - f**2               # Square of eccentricity\n",
    "\n",
    "    sat_lon_rad = math.radians(sat_lon_deg)\n",
    "    x_s = (a + sat_height) * math.cos(sat_lon_rad)\n",
    "    y_s = (a + sat_height) * math.sin(sat_lon_rad)\n",
    "    z_s = 0.0\n",
    "\n",
    "    # ---------------- Step 4: Initialize output arrays ----------------\n",
    "    zenith_angle_arr = np.full(lat_arr.shape, np.nan, dtype=np.float64)\n",
    "    azimuth_angle_arr = np.full(lat_arr.shape, np.nan, dtype=np.float64)\n",
    "\n",
    "    # ---------------- Step 5: Valid point mask ----------------\n",
    "    valid_mask = (~np.isnan(lat_arr)) & (~np.isnan(lon_arr)) & (lat_arr != 0) & (lon_arr != 0)\n",
    "\n",
    "    lat_valid = lat_arr[valid_mask]\n",
    "    lon_valid = lon_arr[valid_mask]\n",
    "    height_valid = height_arr[valid_mask]\n",
    "\n",
    "    # ---------------- Step 6: Convert to radians and compute prime vertical radius N ----------------\n",
    "    lat_rad = np.radians(lat_valid)\n",
    "    lon_rad = np.radians(lon_valid)\n",
    "    sin_lat = np.sin(lat_rad)\n",
    "    cos_lat = np.cos(lat_rad)\n",
    "    N = a / np.sqrt(1 - E2 * sin_lat**2)\n",
    "\n",
    "    # ---------------- Step 7: Ground point Cartesian coordinates ----------------\n",
    "    x_p = (N + height_valid) * cos_lat * np.cos(lon_rad)\n",
    "    y_p = (N + height_valid) * cos_lat * np.sin(lon_rad)\n",
    "    z_p = ((1 - E2) * N + height_valid) * sin_lat\n",
    "\n",
    "    # ---------------- Step 8: Direction vector d = S - P ----------------\n",
    "    x_d = x_s - x_p\n",
    "    y_d = y_s - y_p\n",
    "    z_d = z_s - z_p\n",
    "\n",
    "    # ---------------- Step 9: Local ENU coordinates ----------------\n",
    "    sin_lon = np.sin(lon_rad)\n",
    "    cos_lon = np.cos(lon_rad)\n",
    "    e = -sin_lon * x_d + cos_lon * y_d\n",
    "    n = -sin_lat * cos_lon * x_d - sin_lat * sin_lon * y_d + cos_lat * z_d\n",
    "    u =  cos_lat * cos_lon * x_d + cos_lat * sin_lon * y_d + sin_lat * z_d\n",
    "\n",
    "    # ---------------- Step 10: Compute zenith (Œ∏) and azimuth (œÜ) angles ----------------\n",
    "    theta_deg = 90.0 - np.degrees(np.arctan2(u, np.sqrt(e**2 + n**2)))\n",
    "    phi_deg = np.degrees(np.arctan2(e, n))\n",
    "    phi_deg = np.where(phi_deg < 0, 360.0 + phi_deg, phi_deg)\n",
    "\n",
    "    # ---------------- Step 11: Assign to output arrays ----------------\n",
    "    zenith_angle_arr[valid_mask] = theta_deg\n",
    "    azimuth_angle_arr[valid_mask] = phi_deg\n",
    "\n",
    "    # ---------------- Step 12: Write to NetCDF ----------------\n",
    "    # Zenith angle\n",
    "    if 'satellite_zenith_angle' in nc.variables:\n",
    "        zen_var = nc.variables['satellite_zenith_angle']\n",
    "    else:\n",
    "        lat_dim, lon_dim = nc.variables['latitude'].dimensions\n",
    "        zen_var = nc.createVariable('satellite_zenith_angle', 'f8', (lat_dim, lon_dim))\n",
    "    zen_var[:, :] = zenith_angle_arr\n",
    "    zen_var.units = 'degree'\n",
    "    zen_var.long_name = 'Viewing Zenith Angle (Œ∏)'\n",
    "    zen_var.description = 'Angle between local zenith and line-of-sight to FY-4B satellite'\n",
    "\n",
    "    # Azimuth angle\n",
    "    if 'satellite_azimuth_angle' in nc.variables:\n",
    "        azi_var = nc.variables['satellite_azimuth_angle']\n",
    "    else:\n",
    "        lat_dim, lon_dim = nc.variables['latitude'].dimensions\n",
    "        azi_var = nc.createVariable('satellite_azimuth_angle', 'f8', (lat_dim, lon_dim))\n",
    "    azi_var[:, :] = azimuth_angle_arr\n",
    "    azi_var.units = 'degree'\n",
    "    azi_var.long_name = 'Viewing Azimuth Angle (œÜ)'\n",
    "    azi_var.description = 'Azimuth of satellite direction in local horizon plane (0‚Äì360¬∞)'\n",
    "\n",
    "    # ---------------- Step 13: Close NetCDF ----------------\n",
    "    nc.close()\n",
    "    print(\"‚úÖ Viewing zenith (Œ∏) and azimuth (œÜ) angles have been successfully written to the NetCDF file.\")\n",
    "\n",
    "\n",
    "# ---------------- Example Usage ----------------\n",
    "\n",
    "nc_file_path = \"E:/fengyun/code/output/result.nc\"\n",
    "compute_satellite_angles(nc_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "334cbafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Atmospheric Refraction Correction for Satellite Zenith Angle\n",
    "------------------------------------------------------------\n",
    "\n",
    "This script defines functions to correct satellite viewing zenith angles\n",
    "for the effect of atmospheric refraction, based on local air temperature\n",
    "and pressure from a NetCDF file (e.g., FY-4B LUT).\n",
    "\n",
    "Atmospheric refraction bends the light path toward the surface, making the\n",
    "observed satellite appear slightly higher in the sky than its true\n",
    "geometric position. This correction ensures more accurate satellite\n",
    "geometry and radiative transfer modeling.\n",
    "\n",
    "------------------------------------------------------------------------------\n",
    "üîπ INPUT\n",
    "------------------------------------------------------------------------------\n",
    "The NetCDF file must contain the following variables:\n",
    "\n",
    "- **satellite_zenith_angle**  (2D array, degrees)\n",
    "  Uncorrected zenith angle from the ground to the satellite (0¬∞ = overhead, 90¬∞ = horizon)\n",
    "\n",
    "- **t2m**  (2D array, Kelvin , K)\n",
    "  2-meter air temperature\n",
    "\n",
    "- **sp**  (2D array, Pascals, Pa)\n",
    "  Surface air pressure\n",
    "\n",
    "------------------------------------------------------------------------------\n",
    "üîπ OUTPUT\n",
    "------------------------------------------------------------------------------\n",
    "The function creates or overwrites the following variable in the same NetCDF file:\n",
    "\n",
    "- **satellite_zenith_angle_corrected**  (2D array, degrees)\n",
    "  Satellite zenith angle corrected for atmospheric refraction effects.\n",
    "  Units: degrees\n",
    "  Dimensions: same as `satellite_zenith_angle`\n",
    "  Fill value: NetCDF default for float32\n",
    "\n",
    "------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset, default_fillvals\n",
    "\n",
    "def atmospheric_refraction_correction(local_pressure, local_temp,\n",
    "                                      topocentric_elevation_angle_wo_atmosphere,\n",
    "                                      atmos_refract=0.5667):\n",
    "    \"\"\"\n",
    "    Calculate atmospheric refraction correction for a topocentric elevation angle.\n",
    "    \"\"\"\n",
    "    switch = topocentric_elevation_angle_wo_atmosphere >= -1.0 * (0.26667 + atmos_refract)\n",
    "    delta_e = ((local_pressure / 1010.0) * (283.0 / (273 + local_temp))\n",
    "               * 1.02 / (60 * np.tan(np.radians(\n",
    "                   topocentric_elevation_angle_wo_atmosphere\n",
    "                   + 10.3 / (topocentric_elevation_angle_wo_atmosphere + 5.11))))) * switch\n",
    "    return delta_e\n",
    "\n",
    "\n",
    "def correct_atmospheric_refraction(nc_file_path):\n",
    "    \"\"\"\n",
    "    Apply atmospheric refraction correction to satellite zenith angle in a NetCDF file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nc_file_path : str\n",
    "        Path to the NetCDF file containing 'satellite_zenith_angle', 't2m', and 'sp'.\n",
    "\n",
    "    The function creates a new variable 'satellite_zenith_angle_corrected' in the same file.\n",
    "    \"\"\"\n",
    "    # Open NetCDF file\n",
    "    nc = Dataset(nc_file_path, \"r+\")\n",
    "\n",
    "    # Read variables\n",
    "    zenith   = nc.variables[\"satellite_zenith_angle\"][:]  # degrees\n",
    "    temp_K   = nc.variables[\"t2m\"][:]                     # Kelvin\n",
    "    press_Pa = nc.variables[\"sp\"][:]                      # Pascals\n",
    "\n",
    "    # ---- Unit conversion ----\n",
    "    temp_C    = temp_K - 273.15      # Kelvin ‚Üí Celsius\n",
    "    press_hPa = press_Pa / 100.0     # Pascals ‚Üí hPa\n",
    "\n",
    "    # ---- Convert to elevation angle ----\n",
    "    elev = 90.0 - zenith\n",
    "\n",
    "    # ---- Valid mask: all three inputs are not NaN ----\n",
    "    valid = (~np.isnan(zenith)) & (~np.isnan(temp_C)) & (~np.isnan(press_hPa))\n",
    "\n",
    "    # ---- Initialize corrected zenith angle array as NaN ----\n",
    "    zenith_corrected = np.full_like(zenith, np.nan, dtype=np.float32)\n",
    "\n",
    "    # ---- Apply correction only to valid grid points ----\n",
    "    if np.any(valid):\n",
    "        delta_e = atmospheric_refraction_correction(\n",
    "            local_pressure=press_hPa[valid],\n",
    "            local_temp=temp_C[valid],\n",
    "            topocentric_elevation_angle_wo_atmosphere=elev[valid]\n",
    "        )\n",
    "        elev_corrected = elev[valid] + delta_e\n",
    "        zenith_corrected[valid] = 90.0 - elev_corrected\n",
    "\n",
    "    # ---- Write the corrected zenith angle as a new variable ----\n",
    "    if \"satellite_zenith_angle_corrected\" not in nc.variables:\n",
    "        zen_var = nc.createVariable(\n",
    "            \"satellite_zenith_angle_corrected\", \"f4\",\n",
    "            nc.variables[\"satellite_zenith_angle\"].dimensions,\n",
    "            fill_value=default_fillvals[\"f4\"]\n",
    "        )\n",
    "        zen_var.units = \"degrees\"\n",
    "        zen_var.long_name = \"satellite zenith angle corrected for atmospheric refraction\"\n",
    "\n",
    "    nc.variables[\"satellite_zenith_angle_corrected\"][:] = zenith_corrected\n",
    "    nc.close()\n",
    "\n",
    "\n",
    "# ==== Usage example ====\n",
    "correct_atmospheric_refraction(\"E:/fengyun/code/output/result.nc\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
