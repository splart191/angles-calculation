{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71029c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved successfully: E:/fengyun/code/output/result.nc\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import h5py\n",
    "import os\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "def map_elev_era5_scan_to_lut_safe(\n",
    "    elev_file: str,\n",
    "    era5_file: str,\n",
    "    lut_file: str,\n",
    "    hdf_file: str,\n",
    "    out_file: str\n",
    "):\n",
    "    \"\"\"Map elevation, ERA5 annual mean temperature/pressure, and FY-4B scan time to LUT grid.\"\"\"\n",
    "\n",
    "    # ---------------- 1. Read elevation ----------------\n",
    "    with Dataset(elev_file, 'r') as nc:\n",
    "        lat_elev = nc.variables['latitude'][:]\n",
    "        lon_elev = nc.variables['longitude'][:]\n",
    "        elev     = nc.variables['elevation'][:]\n",
    "\n",
    "    # ---------------- 2. Read LUT ----------------\n",
    "    raw_image = np.fromfile(lut_file)\n",
    "    raw_image = raw_image.reshape(-1, 2)\n",
    "    lat_lut   = raw_image[:, 0].reshape(2748, 2748)\n",
    "    lon_lut   = raw_image[:, 1].reshape(2748, 2748)\n",
    "    mask = (lat_lut > 999) | (lon_lut > 999)\n",
    "    valid = ~mask\n",
    "    ny, nx = lat_lut.shape\n",
    "\n",
    "    # ---------------- 3. Map elevation ----------------\n",
    "    # 用 nearest grid index\n",
    "    def nearest_idx(src_coords, target_coords):\n",
    "        idx = np.searchsorted(src_coords, target_coords, side=\"left\")\n",
    "        idx = np.clip(idx, 1, len(src_coords)-1)\n",
    "        idx = idx - (np.abs(target_coords - src_coords[idx-1]) < np.abs(target_coords - src_coords[idx]))\n",
    "        return idx\n",
    "\n",
    "    lat_idx_elev = nearest_idx(lat_elev, lat_lut)\n",
    "    lon_idx_elev = nearest_idx(lon_elev, lon_lut)\n",
    "    elev_resampled = np.full(lat_lut.shape, np.nan)\n",
    "    elev_resampled[valid] = elev[lat_idx_elev[valid], lon_idx_elev[valid]]\n",
    "\n",
    "    # ---------------- 4. Read ERA5 monthly data and compute annual mean ----------------\n",
    "    with Dataset(era5_file, 'r') as nc:\n",
    "        t2m_monthly = nc.variables['t2m'][:]\n",
    "        sp_monthly  = nc.variables['sp'][:]\n",
    "        lat_era5    = nc.variables['latitude'][:]\n",
    "        lon_era5    = nc.variables['longitude'][:]\n",
    "\n",
    "    t2m_annual = np.mean(t2m_monthly, axis=0)\n",
    "    sp_annual  = np.mean(sp_monthly, axis=0)\n",
    "\n",
    "    # ---------------- 5. Interpolate ERA5 annual data to LUT ----------------\n",
    "    # 如果纬度从北到南，需要翻转\n",
    "    t2m_interp = RegularGridInterpolator(\n",
    "        (lat_era5[::-1], lon_era5),\n",
    "        t2m_annual[::-1, :],\n",
    "        bounds_error=False,\n",
    "        fill_value=np.nan\n",
    "    )\n",
    "    sp_interp = RegularGridInterpolator(\n",
    "        (lat_era5[::-1], lon_era5),\n",
    "        sp_annual[::-1, :],\n",
    "        bounds_error=False,\n",
    "        fill_value=np.nan\n",
    "    )\n",
    "\n",
    "    points = np.stack([lat_lut.ravel(), lon_lut.ravel()], axis=-1)\n",
    "    t2m_resampled = t2m_interp(points).reshape(lat_lut.shape)\n",
    "    sp_resampled  = sp_interp(points).reshape(lat_lut.shape)\n",
    "\n",
    "    # ---------------- 6. Read HDF scan time ----------------\n",
    "    with h5py.File(hdf_file, 'r') as f:\n",
    "        scan_time_raw = f[\"NOMObs/NOMObsTime\"][:]\n",
    "\n",
    "    filename = os.path.basename(hdf_file)\n",
    "    parts = filename.split('_')\n",
    "    start_str = parts[-4]\n",
    "    end_str   = parts[-3]\n",
    "    ts_start = int(start_str + \"000\")\n",
    "    te_end   = int(end_str + \"000\")\n",
    "\n",
    "    # 替换无效时间\n",
    "    ny_raw = scan_time_raw.shape[0]\n",
    "    for i in range(ny_raw):\n",
    "        ts, te = scan_time_raw[i]\n",
    "        if ts == 9999 and te == 9999:\n",
    "            if i < ny_raw // 2:\n",
    "                scan_time_raw[i, 0] = ts_start\n",
    "                scan_time_raw[i, 1] = ts_start\n",
    "            else:\n",
    "                scan_time_raw[i, 0] = te_end\n",
    "                scan_time_raw[i, 1] = te_end\n",
    "\n",
    "    def parse_time(ts_int):\n",
    "        ts_str = f\"{int(ts_int):017d}\"\n",
    "        dt = datetime.strptime(ts_str[:14], \"%Y%m%d%H%M%S\")\n",
    "        ms = int(ts_str[14:])\n",
    "        return dt + timedelta(milliseconds=ms)\n",
    "\n",
    "    def datetime_to_unix(dt):\n",
    "        return dt.replace(tzinfo=timezone.utc).timestamp()\n",
    "\n",
    "    def unix_to_int(ts):\n",
    "        dt = datetime.fromtimestamp(ts, tz=timezone.utc)\n",
    "        ms = int(dt.microsecond / 1000)\n",
    "        return int(dt.strftime(\"%Y%m%d%H%M%S\") + f\"{ms:03d}\")\n",
    "\n",
    "    # ---------------- 7. Interpolate scan time ----------------\n",
    "    scan_time_sec = np.full((ny, nx), np.nan, dtype=np.float64)\n",
    "    for i in range(ny):\n",
    "        ts_int, te_int = scan_time_raw[i]\n",
    "        dt_start = parse_time(ts_int)\n",
    "        dt_end   = parse_time(te_int)\n",
    "        ts_sec = datetime_to_unix(dt_start)\n",
    "        te_sec = datetime_to_unix(dt_end)\n",
    "\n",
    "        valid_cols = np.where(valid[i, :])[0]\n",
    "        n_valid = len(valid_cols)\n",
    "        if n_valid > 0:\n",
    "            scan_time_sec[i, valid_cols] = np.linspace(ts_sec, te_sec, n_valid)\n",
    "\n",
    "    scan_time_int = np.full((ny, nx), 0, dtype=np.int64)\n",
    "    valid_idx = ~np.isnan(scan_time_sec)\n",
    "    scan_time_int[valid_idx] = np.vectorize(unix_to_int)(scan_time_sec[valid_idx])\n",
    "\n",
    "    # ---------------- 8. Save to NetCDF ----------------\n",
    "    ds_out = Dataset(out_file, 'w', format='NETCDF4')\n",
    "    ds_out.createDimension('y', ny)\n",
    "    ds_out.createDimension('x', nx)\n",
    "\n",
    "    lat_var  = ds_out.createVariable('latitude', 'f8', ('y','x'))\n",
    "    lon_var  = ds_out.createVariable('longitude', 'f8', ('y','x'))\n",
    "    elev_var = ds_out.createVariable('altitude', 'f8', ('y','x'), fill_value=np.nan)\n",
    "    t2m_var  = ds_out.createVariable('t2m', 'f8', ('y','x'), fill_value=np.nan)\n",
    "    sp_var   = ds_out.createVariable('sp', 'f8', ('y','x'), fill_value=np.nan)\n",
    "    scan_var = ds_out.createVariable('scan_time', 'i8', ('y','x'), fill_value=0)\n",
    "\n",
    "    lat_var[:, :]   = lat_lut\n",
    "    lon_var[:, :]   = lon_lut\n",
    "    elev_var[:, :]  = elev_resampled\n",
    "    t2m_var[:, :]   = t2m_resampled\n",
    "    sp_var[:, :]    = sp_resampled\n",
    "    scan_var[:, :]  = scan_time_int\n",
    "\n",
    "    lat_var.units  = 'degrees_north'\n",
    "    lon_var.units  = 'degrees_east'\n",
    "    elev_var.units = 'm'\n",
    "    t2m_var.units  = 'K'\n",
    "    sp_var.units   = 'Pa'\n",
    "    scan_var.units = 'YYYYMMDDHHMMSSsss (UTC)'\n",
    "\n",
    "    elev_var.description = 'High-resolution elevation mapped to LUT grid'\n",
    "    t2m_var.description  = 'ERA5 annual mean 2m temperature mapped to LUT grid'\n",
    "    sp_var.description   = 'ERA5 annual mean surface pressure mapped to LUT grid'\n",
    "    scan_var.description = 'Scan time interpolated from start/end time of each line, UTC, millisecond precision'\n",
    "\n",
    "    ds_out.close()\n",
    "    print(\"Saved successfully:\", out_file)\n",
    "\n",
    "\n",
    "# ================= Example usage =================\n",
    "elev_file = \"E:/fengyun/code/input/world_ll_elev_0.05deg.nc4\"\n",
    "era5_file = \"E:/fengyun/code/input/2024monthly.nc\"\n",
    "lut_file  = \"E:/fengyun/code/input/FY4B-_DISK_1050E_GEO_NOM_LUT_20240227000000_4000M_V0001.raw\"\n",
    "hdf_file  = \"E:/fengyun/code/input/FY4B-_AGRI--_N_DISK_1050E_L1-_FDI-_MULT_NOM_20240923040000_20240923041459_4000M_V0001.HDF\"\n",
    "out_file  = \"E:/fengyun/code/output/result.nc\"\n",
    "\n",
    "map_elev_era5_scan_to_lut_safe(elev_file, era5_file, lut_file, hdf_file, out_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbefdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\27144\\AppData\\Local\\Temp\\ipykernel_15260\\69634668.py:42: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  time_grid[valid_mask] = np.vectorize(int_to_datetime)(scan_time_int[valid_mask])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "太阳位置计算完成并保存回 E:/fengyun/code/output/result.nc\n"
     ]
    }
   ],
   "source": [
    "###################### SPA-Based Solar Geometry Computation #######################\n",
    "# This script reads a LUT NetCDF file containing elevation, ERA5 annual mean \n",
    "# temperature and pressure, and FY-4B scan time information. \n",
    "# It computes solar position parameters (zenith, elevation, azimuth, etc.) \n",
    "# using the SPA algorithm implemented in pvlib, and writes the results \n",
    "# back to the same NetCDF file.\n",
    "###################################################################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from netCDF4 import Dataset\n",
    "import pvlib\n",
    "\n",
    "def compute_solarposition_nc(nc_file, delta_t=67.0, numthreads=4):\n",
    "    \"\"\"\n",
    "    Compute solar position (zenith, elevation, azimuth, etc.) for each pixel in\n",
    "    a LUT NetCDF file using the SPA algorithm and save results back to the file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nc_file : str\n",
    "        Path to the NetCDF file containing 'latitude', 'longitude', 'altitude', \n",
    "        'scan_time', 't2m', and 'sp' variables.\n",
    "    delta_t : float, optional\n",
    "        Difference between Earth rotation time and UT1 time (in seconds).\n",
    "    numthreads : int, optional\n",
    "        Number of threads used by pvlib.solarposition.spa_python.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------------- 1. Open NetCDF file and read variables ----------------\n",
    "    ds = Dataset(nc_file, 'r+')\n",
    "    lat = ds.variables['latitude'][:, :]\n",
    "    lon = ds.variables['longitude'][:, :]\n",
    "    elev = ds.variables['altitude'][:, :]\n",
    "    scan_time_int = ds.variables['scan_time'][:, :]\n",
    "    t2m = ds.variables['t2m'][:, :]   # ERA5 annual mean temperature (K)\n",
    "    sp  = ds.variables['sp'][:, :]    # ERA5 annual mean surface pressure (Pa)\n",
    "\n",
    "    ny, nx = lat.shape\n",
    "    valid_mask = ~np.isnan(lat) & (scan_time_int > 0)\n",
    "\n",
    "    # ---------------- 2. Convert integer scan time to pandas.DatetimeIndex ----------------\n",
    "    def int_to_datetime(ts_int):\n",
    "        ts_str = f\"{int(ts_int):017d}\"  # Ensure 17 digits\n",
    "        dt = pd.to_datetime(ts_str[:14], format=\"%Y%m%d%H%M%S\", utc=True)\n",
    "        ms = int(ts_str[14:])\n",
    "        return dt + pd.Timedelta(milliseconds=ms)\n",
    "\n",
    "    time_grid = np.empty((ny, nx), dtype='datetime64[ms]')\n",
    "    time_grid[valid_mask] = np.vectorize(int_to_datetime)(scan_time_int[valid_mask])\n",
    "    time_grid[~valid_mask] = np.datetime64('NaT')\n",
    "\n",
    "    # ---------------- 3. Flatten valid pixels ----------------\n",
    "    lat_flat = lat[valid_mask]\n",
    "    lon_flat = lon[valid_mask]\n",
    "    elev_flat = elev[valid_mask]\n",
    "    time_flat = pd.DatetimeIndex(time_grid[valid_mask].ravel())\n",
    "    pressure_flat = sp[valid_mask]\n",
    "    temperature_flat = t2m[valid_mask] - 273.15  # Convert to Celsius\n",
    "\n",
    "    # ---------------- 4. Compute solar position using pvlib ----------------\n",
    "    solpos_flat = pvlib.solarposition.spa_python(\n",
    "        time=time_flat,\n",
    "        latitude=lat_flat,\n",
    "        longitude=lon_flat,\n",
    "        altitude=elev_flat,\n",
    "        pressure=pressure_flat,\n",
    "        temperature=temperature_flat,\n",
    "        delta_t=delta_t,\n",
    "        how='numpy',\n",
    "        numthreads=numthreads\n",
    "    )\n",
    "\n",
    "    # ---------------- 5. Reshape results back to grid ----------------\n",
    "    def create_grid(var_name):\n",
    "        grid = np.full((ny, nx), np.nan, dtype=np.float32)\n",
    "        grid[valid_mask] = solpos_flat[var_name].values\n",
    "        return grid\n",
    "\n",
    "    apparent_zenith_grid    = create_grid('apparent_zenith')\n",
    "    zenith_grid             = create_grid('zenith')\n",
    "    apparent_elevation_grid = create_grid('apparent_elevation')\n",
    "    elevation_grid          = create_grid('elevation')\n",
    "    azimuth_grid            = create_grid('azimuth')\n",
    "    eq_time_grid            = create_grid('equation_of_time')\n",
    "\n",
    "    # ---------------- 6. Write results back to NetCDF ----------------\n",
    "    def create_or_replace_var(name, data, units):\n",
    "        if name in ds.variables:\n",
    "            ds.variables[name][:] = data\n",
    "        else:\n",
    "            var = ds.createVariable(name, 'f4', ('y', 'x'), fill_value=np.nan)\n",
    "            var[:, :] = data\n",
    "            var.units = units\n",
    "\n",
    "    create_or_replace_var('apparent_zenith', apparent_zenith_grid, 'degrees')\n",
    "    create_or_replace_var('zenith', zenith_grid, 'degrees')\n",
    "    create_or_replace_var('apparent_elevation', apparent_elevation_grid, 'degrees')\n",
    "    create_or_replace_var('elevation_solar', elevation_grid, 'degrees')\n",
    "    create_or_replace_var('azimuth', azimuth_grid, 'degrees')\n",
    "    create_or_replace_var('equation_of_time', eq_time_grid, 'minutes')\n",
    "\n",
    "    ds.close()\n",
    "    print(f\"Solar position computation completed and saved to {nc_file}\")\n",
    "\n",
    "\n",
    "# ---------------- Example usage ----------------\n",
    "nc_file = \"E:/fengyun/code/output/result.nc\"\n",
    "compute_solarposition_nc(nc_file, delta_t=69.1322, numthreads=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b38e411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Viewing zenith (θ) and azimuth (φ) angles have been successfully written to the NetCDF file.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FY-4B Satellite Viewing Angle Computation\n",
    "\n",
    "This script provides a function to compute viewing zenith (θ) and azimuth (φ)\n",
    "angles from the FY-4B geostationary satellite to the ground, based on\n",
    "latitude, longitude, and terrain elevation grids in a NetCDF file.\n",
    "\n",
    "The computed angles are written back to the same NetCDF file as two variables:\n",
    "- satellite_zenith_angle: Zenith angle in degrees (0 = zenith, 90 = horizon)\n",
    "- satellite_azimuth_angle: Azimuth angle in degrees (0–360°, clockwise from North)\n",
    "\n",
    "Parameters can be adjusted for satellite longitude and orbit height.\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "def compute_satellite_angles(nc_file: str, sat_lon_deg: float = 105.0, sat_height: float = 35786000.0):\n",
    "    \"\"\"\n",
    "    Compute viewing zenith angle (θ) and azimuth angle (φ) from FY-4B satellite\n",
    "    to the ground, and write them to the input NetCDF file.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    nc_file : str\n",
    "        Input/output NetCDF file containing 'latitude', 'longitude', and 'altitude'.\n",
    "    sat_lon_deg : float, optional\n",
    "        Satellite longitude in degrees (default is 105.0° for FY-4B).\n",
    "    sat_height : float, optional\n",
    "        Satellite orbit height in meters (default is 35786000 m).\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------------- Step 1: Open NetCDF file ----------------\n",
    "    nc = Dataset(nc_file, 'r+')\n",
    "\n",
    "    # ---------------- Step 2: Read latitude, longitude, and altitude ----------------\n",
    "    lat_arr = np.array(nc.variables['latitude'][:], dtype=np.float64)\n",
    "    lon_arr = np.array(nc.variables['longitude'][:], dtype=np.float64)\n",
    "    height_arr = np.array(nc.variables['altitude'][:], dtype=np.float64)\n",
    "\n",
    "    # ---------------- Step 3: Satellite and Earth parameters (GRS80) ----------------\n",
    "    a = 6378137.0                   # Equatorial radius (m)\n",
    "    f = 1 / 298.257222101           # Flattening\n",
    "    E2 = 2 * f - f**2               # Square of eccentricity\n",
    "\n",
    "    sat_lon_rad = math.radians(sat_lon_deg)\n",
    "    x_s = (a + sat_height) * math.cos(sat_lon_rad)\n",
    "    y_s = (a + sat_height) * math.sin(sat_lon_rad)\n",
    "    z_s = 0.0\n",
    "\n",
    "    # ---------------- Step 4: Initialize output arrays ----------------\n",
    "    zenith_angle_arr = np.full(lat_arr.shape, np.nan, dtype=np.float64)\n",
    "    azimuth_angle_arr = np.full(lat_arr.shape, np.nan, dtype=np.float64)\n",
    "\n",
    "    # ---------------- Step 5: Valid point mask ----------------\n",
    "    valid_mask = (~np.isnan(lat_arr)) & (~np.isnan(lon_arr)) & (lat_arr != 0) & (lon_arr != 0)\n",
    "\n",
    "    lat_valid = lat_arr[valid_mask]\n",
    "    lon_valid = lon_arr[valid_mask]\n",
    "    height_valid = height_arr[valid_mask]\n",
    "\n",
    "    # ---------------- Step 6: Convert to radians and compute prime vertical radius N ----------------\n",
    "    lat_rad = np.radians(lat_valid)\n",
    "    lon_rad = np.radians(lon_valid)\n",
    "    sin_lat = np.sin(lat_rad)\n",
    "    cos_lat = np.cos(lat_rad)\n",
    "    N = a / np.sqrt(1 - E2 * sin_lat**2)\n",
    "\n",
    "    # ---------------- Step 7: Ground point Cartesian coordinates ----------------\n",
    "    x_p = (N + height_valid) * cos_lat * np.cos(lon_rad)\n",
    "    y_p = (N + height_valid) * cos_lat * np.sin(lon_rad)\n",
    "    z_p = ((1 - E2) * N + height_valid) * sin_lat\n",
    "\n",
    "    # ---------------- Step 8: Direction vector d = S - P ----------------\n",
    "    x_d = x_s - x_p\n",
    "    y_d = y_s - y_p\n",
    "    z_d = z_s - z_p\n",
    "\n",
    "    # ---------------- Step 9: Local ENU coordinates ----------------\n",
    "    sin_lon = np.sin(lon_rad)\n",
    "    cos_lon = np.cos(lon_rad)\n",
    "    e = -sin_lon * x_d + cos_lon * y_d\n",
    "    n = -sin_lat * cos_lon * x_d - sin_lat * sin_lon * y_d + cos_lat * z_d\n",
    "    u =  cos_lat * cos_lon * x_d + cos_lat * sin_lon * y_d + sin_lat * z_d\n",
    "\n",
    "    # ---------------- Step 10: Compute zenith (θ) and azimuth (φ) angles ----------------\n",
    "    theta_deg = 90.0 - np.degrees(np.arctan2(u, np.sqrt(e**2 + n**2)))\n",
    "    phi_deg = np.degrees(np.arctan2(e, n))\n",
    "    phi_deg = np.where(phi_deg < 0, 360.0 + phi_deg, phi_deg)\n",
    "\n",
    "    # ---------------- Step 11: Assign to output arrays ----------------\n",
    "    zenith_angle_arr[valid_mask] = theta_deg\n",
    "    azimuth_angle_arr[valid_mask] = phi_deg\n",
    "\n",
    "    # ---------------- Step 12: Write to NetCDF ----------------\n",
    "    # Zenith angle\n",
    "    if 'satellite_zenith_angle' in nc.variables:\n",
    "        zen_var = nc.variables['satellite_zenith_angle']\n",
    "    else:\n",
    "        lat_dim, lon_dim = nc.variables['latitude'].dimensions\n",
    "        zen_var = nc.createVariable('satellite_zenith_angle', 'f8', (lat_dim, lon_dim))\n",
    "    zen_var[:, :] = zenith_angle_arr\n",
    "    zen_var.units = 'degree'\n",
    "    zen_var.long_name = 'Viewing Zenith Angle (θ)'\n",
    "    zen_var.description = 'Angle between local zenith and line-of-sight to FY-4B satellite'\n",
    "\n",
    "    # Azimuth angle\n",
    "    if 'satellite_azimuth_angle' in nc.variables:\n",
    "        azi_var = nc.variables['satellite_azimuth_angle']\n",
    "    else:\n",
    "        lat_dim, lon_dim = nc.variables['latitude'].dimensions\n",
    "        azi_var = nc.createVariable('satellite_azimuth_angle', 'f8', (lat_dim, lon_dim))\n",
    "    azi_var[:, :] = azimuth_angle_arr\n",
    "    azi_var.units = 'degree'\n",
    "    azi_var.long_name = 'Viewing Azimuth Angle (φ)'\n",
    "    azi_var.description = 'Azimuth of satellite direction in local horizon plane (0–360°)'\n",
    "\n",
    "    # ---------------- Step 13: Close NetCDF ----------------\n",
    "    nc.close()\n",
    "    print(\"✅ Viewing zenith (θ) and azimuth (φ) angles have been successfully written to the NetCDF file.\")\n",
    "\n",
    "\n",
    "# ---------------- Example Usage ----------------\n",
    "\n",
    "nc_file_path = \"E:/fengyun/code/output/result.nc\"\n",
    "compute_satellite_angles(nc_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "334cbafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from netCDF4 import Dataset, default_fillvals\n",
    "\n",
    "def atmospheric_refraction_correction(local_pressure, local_temp,\n",
    "                                      topocentric_elevation_angle_wo_atmosphere,\n",
    "                                      atmos_refract=0.5667):\n",
    "    \"\"\"\n",
    "    Calculate atmospheric refraction correction for a topocentric elevation angle.\n",
    "    \"\"\"\n",
    "    switch = topocentric_elevation_angle_wo_atmosphere >= -1.0 * (0.26667 + atmos_refract)\n",
    "    delta_e = ((local_pressure / 1010.0) * (283.0 / (273 + local_temp))\n",
    "               * 1.02 / (60 * np.tan(np.radians(\n",
    "                   topocentric_elevation_angle_wo_atmosphere\n",
    "                   + 10.3 / (topocentric_elevation_angle_wo_atmosphere + 5.11))))) * switch\n",
    "    return delta_e\n",
    "\n",
    "\n",
    "def correct_atmospheric_refraction(nc_file_path):\n",
    "    \"\"\"\n",
    "    Apply atmospheric refraction correction to satellite zenith angle in a NetCDF file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nc_file_path : str\n",
    "        Path to the NetCDF file containing 'satellite_zenith_angle', 't2m', and 'sp'.\n",
    "\n",
    "    The function creates a new variable 'satellite_zenith_angle_corrected' in the same file.\n",
    "    \"\"\"\n",
    "    # Open NetCDF file\n",
    "    nc = Dataset(nc_file_path, \"r+\")\n",
    "\n",
    "    # Read variables\n",
    "    zenith   = nc.variables[\"satellite_zenith_angle\"][:]  # degrees\n",
    "    temp_K   = nc.variables[\"t2m\"][:]                     # Kelvin\n",
    "    press_Pa = nc.variables[\"sp\"][:]                      # Pascals\n",
    "\n",
    "    # ---- Unit conversion ----\n",
    "    temp_C    = temp_K - 273.15      # Kelvin → Celsius\n",
    "    press_hPa = press_Pa / 100.0     # Pascals → hPa\n",
    "\n",
    "    # ---- Convert to elevation angle ----\n",
    "    elev = 90.0 - zenith\n",
    "\n",
    "    # ---- Valid mask: all three inputs are not NaN ----\n",
    "    valid = (~np.isnan(zenith)) & (~np.isnan(temp_C)) & (~np.isnan(press_hPa))\n",
    "\n",
    "    # ---- Initialize corrected zenith angle array as NaN ----\n",
    "    zenith_corrected = np.full_like(zenith, np.nan, dtype=np.float32)\n",
    "\n",
    "    # ---- Apply correction only to valid grid points ----\n",
    "    if np.any(valid):\n",
    "        delta_e = atmospheric_refraction_correction(\n",
    "            local_pressure=press_hPa[valid],\n",
    "            local_temp=temp_C[valid],\n",
    "            topocentric_elevation_angle_wo_atmosphere=elev[valid]\n",
    "        )\n",
    "        elev_corrected = elev[valid] + delta_e\n",
    "        zenith_corrected[valid] = 90.0 - elev_corrected\n",
    "\n",
    "    # ---- Write the corrected zenith angle as a new variable ----\n",
    "    if \"satellite_zenith_angle_corrected\" not in nc.variables:\n",
    "        zen_var = nc.createVariable(\n",
    "            \"satellite_zenith_angle_corrected\", \"f4\",\n",
    "            nc.variables[\"satellite_zenith_angle\"].dimensions,\n",
    "            fill_value=default_fillvals[\"f4\"]\n",
    "        )\n",
    "        zen_var.units = \"degrees\"\n",
    "        zen_var.long_name = \"satellite zenith angle corrected for atmospheric refraction\"\n",
    "\n",
    "    nc.variables[\"satellite_zenith_angle_corrected\"][:] = zenith_corrected\n",
    "    nc.close()\n",
    "\n",
    "\n",
    "# ==== Usage example ====\n",
    "correct_atmospheric_refraction(\"E:/fengyun/code/output/result.nc\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
